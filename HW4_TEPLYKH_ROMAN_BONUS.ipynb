{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment No. 4 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, write your implementation within the designated blocks:\n",
    "```python\n",
    "...\n",
    "### BEGIN Solution\n",
    "\n",
    "# >>> your solution here <<<\n",
    "\n",
    "### END Solution\n",
    "...\n",
    "```\n",
    "\n",
    "Write your theoretical derivations within such blocks:\n",
    "```markdown\n",
    "**BEGIN Solution**\n",
    "\n",
    "<!-- >>> your derivation here <<< -->\n",
    "\n",
    "**END Solution**\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\LaTeX$ in Jupyter\n",
    "Jupyter has constantly improving $\\LaTeX$ support. Below are the basic methods to\n",
    "write **neat, tidy, and well typeset** equations in your notebooks:\n",
    "* to write an **inline** equation use \n",
    "```markdown\n",
    "$ you latex equation here $\n",
    "```\n",
    "* to write an equation, that is **displayed on a separate line** use \n",
    "```markdown\n",
    "$$ you latex equation here $$\n",
    "```\n",
    "* to write a **block of equations** use \n",
    "```markdown\n",
    "\\begin{align}\n",
    "    left-hand-side\n",
    "        &= right-hand-side on line 1\n",
    "        \\\\\n",
    "        &= right-hand-side on line 2\n",
    "        \\\\\n",
    "        &= right-hand-side on the last line\n",
    "\\end{align}\n",
    "```\n",
    "The **ampersand** (`&`) aligns the equations horizontally and the **double backslash**\n",
    "(`\\\\`) creates a new line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly / outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will need to work through a modified version of\n",
    "the SVDD model (**support vector data description**) -- a model for outlier\n",
    "detection, and show some theoretical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we have a dataset $x_1, \\ldots, x_l$ from some set $\\mathcal{X}$.\n",
    "\n",
    "We apply the kernel trick using the kernel $K \\colon \\mathcal{X} \\times \\mathcal{X}\n",
    "\\to \\mathbb{R}$ of the Hilbert space $\\bigl(\\mathcal{H}, \\langle \\cdot,\n",
    "\\cdot \\rangle\\big)$ with the feature mapping $\\phi(\\cdot)\\colon \\mathcal{X}\n",
    "\\to \\mathcal{H}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that $\\nu \\in (0, 1)$, and $C_i > 0$ with $\\sum_{i=1}^l C_i = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVDD model (kernelized) is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\underset{R, h, \\xi}{\\text{minimize}}\n",
    "      & & R + \\frac1\\nu \\sum_{i=1}^l C_i \\xi_i\n",
    "          \\,, \\\\\n",
    "    & \\text{subject to}\n",
    "      & & \\|\\phi(x_i) - h \\|^2 \\leq R + \\xi_i\n",
    "          \\,, \\\\\n",
    "    & & & \\xi_i \\geq 0\n",
    "          \\,.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (3 pt.): Can $R$ be negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the SVDD problem with an extra constraint $R \\geq 0$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\underset{R, h, \\xi}{\\text{minimize}}\n",
    "      & & R + \\frac1\\nu \\sum_{i=1}^l C_i \\xi_i\n",
    "          \\,, \\\\\n",
    "    & \\text{subject to}\n",
    "      & & \\|\\phi(x_i) - h \\|^2 \\leq R + \\xi_i\n",
    "          \\,, \\\\\n",
    "    & & & \\xi_i \\geq 0\n",
    "          \\,, \\\\\n",
    "    & & & R \\geq 0\n",
    "          \\,.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R \\geq 0$ constraint is a nuisance.\n",
    "\n",
    "* Show, that if $(R, \\xi, h)$ has $R < 0$, then it **is not better** than a\n",
    "certain other feasible candidate $(\\hat{R}, \\hat{\\xi}, \\hat{h})$ with $\\hat{R} \\geq 0$.\n",
    "* Argue that it is, in fact, **redundant**, i.e. the problem formulations\n",
    "**with it** and **without it** have identical solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point 1**  \n",
    "Let suppose $ R < 0 $, which means, that $ R = -\\| R \\| $. From this mention, implies, that:\n",
    "$$\n",
    "\\|\\phi(x_i) - h \\|^2  \\leq - \\| R \\| + \\xi_i, \\text{ implies } \\xi_i \\geq | R | + \\|\\phi(x_i) - h \\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With constraint above, we can rewrite objective function:\n",
    "$$\n",
    "R + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\xi_i \\geq  R + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\left [ \\| R \\| + \\| \\phi(x_i) - h \\|^2 \\right ] = \\| R \\| \\left ( -1 + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\right ) + \\sum_{i = 1}^l C_i \\| \\phi(x_i) - h \\|^2 = \\\\\n",
    "= R \\dfrac{\\nu - 1}{\\nu} + \\sum_{i = 1}^l C_i \\|\\phi(x_i) - h \\|^2 = \\| R \\| \\dfrac{1 - \\nu}{\\nu} + \\sum_{i = 1}^l C_i \\|\\phi(x_i) - h \\|^2 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our convinience, we can let, that  $ \\mathcal{R} = |R| \\dfrac{ 1 - \\nu}{\\nu} \\geq 0 $ and $ \\mathcal{ \\xi }_i = \\| \\phi(x_i) - h \\|^2 $, we sat, that\n",
    "$$\n",
    "R + \\sum_{i=1}^l C_i \\xi_i \\geq \\mathcal{R} + \\sum_{i = 1}^l C_i \\mathcal{\\xi}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point 2**  \n",
    "Assume $R>0$. From the constrain:\n",
    "$$\n",
    "\\| \\phi(x_i) - h \\|^2  \\leq R + \\xi_i \\rightarrow \\xi_i \\geq - R + \\| \\phi(x_i) - h \\|^2\n",
    "$$\n",
    "After it, we can consider the next objective function:\n",
    "$$\n",
    "R + \\frac{1}{\\nu} \\sum_{i = 1}^l C_i \\xi_i \\geq R + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\left [ - R + \\| \\phi(x_i) - h \\|^2 \\right ] = \\\\ = R \\left [ 1 - \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\right ] + \\sum_{i = 1}^l C_i \\| \\phi(x_i) - h \\|^2 = R \\dfrac{ \\nu - 1}{\\nu} + \\sum_{i = 1}^l C_i \\|\\phi(x_i) - h \\|^2\n",
    "$$\n",
    "Here, we can see, that new solution in case, where $ \\left ( \\mathcal{R}, \\mathcal{\\xi}, \\mathcal{h} \\right ) $ has similar form as it was in initial task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (2 pt.): Can $\\xi_i > 0$ for all $i$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argue if $(R, \\xi, h)$ is a solution, then $\\xi_i = 0$ for at least one $i=1,\\,\\ldots,\\,l$. Let $\\bar{\\xi} = \\min_{j=1}^l \\xi_j$.\n",
    "\n",
    "**HINT** Use an argument similar to Task $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, that for some $ i, \\bar{C} $ corresponds $ \\bar{\\xi} = 0 $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can look more precisely at objective function with different $ \\xi $:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "R + \\dfrac{1}{\\nu} \\sum_{ i = 1 }^l C_i \\xi_i = R + \\dfrac{1}{\\nu} \\bar{C} \\bar{\\xi_i} + \\dfrac{1}{\\nu} \\sum_{ i \\neq j } C_j \\xi_j\n",
    "$$\n",
    "\n",
    "and $ \\xi_i \\neq \\bar{\\xi_i} \\implies $, that quality above we can look as a function of one parameter $ \\xi_i $ and we can say, that if $ f( \\bar{\\xi} ) $ always not better, that $ f ( \\xi ) $. From the previous conclusion, we can say, that for some $ i : \\xi_i = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (2 pt.): The Lagrangian and KKT conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, write out the Lagrangian function of the problem and write out the KKT conditions\n",
    "* Lagrangian\n",
    "* the first order conditions\n",
    "* the complementary slackness conditions\n",
    "* the primal and dual constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "    & \\underset{R, h, \\xi}{\\text{minimize}}\n",
    "      & & R + \\frac1\\nu \\sum_{i=1}^l C_i \\xi_i\n",
    "          \\,, \\\\\n",
    "    & \\text{subject to}\n",
    "      & & \\|\\phi(x_i) - h \\|^2 \\leq R + \\xi_i\n",
    "          \\,, \\\\\n",
    "    & & & \\xi_i \\geq 0\n",
    "          \\,.\n",
    "\\end{aligned}$$\n",
    "\n",
    "Lagrangian is:\n",
    "$$\n",
    "L(R, h, \\xi_i, \\alpha_i, \\beta_i) = R + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\xi_i  - \\sum_i \\alpha_i \\left( R + \\xi_i  - \\|\\ phi(x_i) - h \\|^2 \\right) - \\sum_i \\beta_i \\xi_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first order conditions:\n",
    "$$\n",
    "\\dfrac{ \\partial L }{ \\partial R } = 0: \\implies \\sum_i \\alpha_i = 1 \\\\\n",
    "\\dfrac{\\partial L}{\\partial h} = 0, \\dfrac{\\partial }{\\partial h} \\left [ R + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\xi_i  - \\sum_i \\alpha_i \\left( R + \\xi_i  - \\|\\ phi(x_i) - h \\|^2 \\right) - \\sum_i \\beta_i \\xi_i \\right ] \\implies h = \\dfrac{\\sum_i \\alpha_i \\phi(x_i)}{\\sum_i \\alpha_i} = \\sum_i \\alpha_i \\phi(x_i) \\\\\n",
    "\\dfrac{\\partial L}{\\partial \\xi_i} = 0, \\dfrac{\\partial }{\\partial \\xi_i} \\left [ R + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\xi_i  - \\sum_i \\alpha_i \\left( R + \\xi_i  - \\|\\ phi(x_i) - h \\|^2 \\right) - \\sum_i \\beta_i \\xi_i \\right ] \\implies \\dfrac{C_i}{\\nu} - \\alpha_i - \\beta_i = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complementary slackness conditions:\n",
    "$$\n",
    "\\alpha_i \\left [ R + \\xi_i  - \\| \\phi(x_i) - h\\|^2 \\right ] = 0 \\text{ and } \\beta_i \\xi_i = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primal and dual constraints:\n",
    "$$\n",
    "\\xi_i \\geq 0 \\implies \\begin{cases}\n",
    "    \\alpha_i \\geq 0 \\\\\n",
    "    \\beta_i \\geq 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (2 pt.): Simplifying the Lagrangian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down $h$ as a function of transformed input data and dual coefficients,\n",
    "and using the first order conditions rewrite the Lagrangian in such a way, that\n",
    "it only contains dual variables and evaluations of the kernel $K(\\cdot, \\cdot)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at Lagrangian:\n",
    "$$\n",
    "L(R, h, \\alpha_i, \\beta_i, \\xi_i) = R + \\dfrac{1}{\\nu} \\sum_i C_i \\xi_i - \\sum_i \\alpha_i \\left [ R + \\xi_i  - \\| \\phi(x_i) - h \\|^2 \\right ] - \\sum_i \\beta_i \\xi_i\n",
    "$$\n",
    "\n",
    "Now, we can use first order conditions:\n",
    "$$\n",
    "h = \\sum_i \\alpha_i \\phi(x_i) \\text{ and } \\dfrac{C_i}{\\nu} - \\alpha_i - \\beta_i = 0\n",
    "$$\n",
    "and use it for future convinience, and write:\n",
    "$$\n",
    "R + \\sum_i \\left [ \\dfrac{C_i}{\\nu} - \\beta_i \\right ] \\xi_i - \\sum_i \\alpha_i \\left [ R + \\xi_i  - (K(x_i, x_i) - 2 \\sum_j \\alpha_j K(x_i, x_j) + \\sum_j \\alpha_j^2 K(x_j, x_j) \\right ] = \\\\ = R + \\sum_i \\left [ \\dfrac{ C_i }{ \\nu } - \\beta_i - \\alpha_i \\right ] \\xi_i - \\sum_i \\alpha_i R + \\sum_i \\alpha_i K(x_i, x_i) - 2 \\sum_{i, j} \\alpha_i \\alpha_j K(x_i, x_j) + \\sum_{i,j} \\alpha_i \\alpha_j^2 K(x_j, x_j) =\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_i \\alpha_i K(x_i, x_i) - 2 \\sum_{i, j} \\alpha_i \\alpha_j K(x_i, x_j) + \\sum_{j} \\alpha_j^2 K(x_j, x_j) \\sum_{i} \\alpha_i = \\\\\n",
    "= \\sum_i \\alpha_i \\left [ K(x_i, x_i) - 2 \\sum_{j} \\alpha_j K(x_i, x_j) + \\sum_{j} \\alpha_j^2 K(x_j, x_j) \\right ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 (2 pt.): The dual problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Carefully eliminate $\\beta_i$ from the KKT conditions, and write\n",
    "down the inequality constraints for the dual variables $\\alpha_i$,\n",
    "implied by the FOC.\n",
    "\n",
    "* Combine your results into dual problem (minimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first order conditions we have:\n",
    "$$\n",
    "\\dfrac{C_i}{\\nu} - \\alpha_i - \\beta_i = 0 \\implies \\beta_i = \\dfrac{C_i}{\\nu} - \\alpha_i\n",
    "$$\n",
    "\n",
    "Moreover, $ \\beta_i > 0, \\alpha_i > 0 $.\n",
    "\n",
    "After conclusions above, we can rewrite constraints for $ \\alpha_i $ as $ 0 \\leq \\alpha_i \\leq \\dfrac{C_i}{\\nu} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result, dual problem is:\n",
    "$$\n",
    "\\underset{\\alpha}{max} \\left [  \\sum_i \\alpha_i \\left(K(x_i, x_i) - 2 \\sum_{j} \\alpha_j K(x_i, x_j) + \\sum_{j} \\alpha_j^2 K(x_j, x_j)\\right) \\right ] \\\\\n",
    "\\text{ with subjects: } 0 \\leq \\alpha_i \\leq \\dfrac{C_i}{ \\nu } \\text{ and } \\sum \\alpha_i = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (2 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, you have solved the dual and have optimal $(\\alpha^*_i)_{i=1}^l$ and\n",
    "$ h^* = \\sum_{i=1}^l \\alpha^*_i \\phi(x_i)$.\n",
    "\n",
    "Let $M = \\{i\\colon \\alpha^*_i \\in \\left(0, \\tfrac{C_i}{\\nu}\\right)\\}$ and suppose $M \\neq \\emptyset$.\n",
    "\n",
    "* Derive the expression for the optimal value of $R$ from this and the\n",
    "complementary sclackness conditions.\n",
    "\n",
    "* Write out the decision function for an arbitrary $x\\in \\mathcal{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was sayed, $ R $ is the margin between hyperplane and origin points. This hyperplane is constructed by support vectors, for which $ \\alpha_i = \\dfrac{ C_i }{ \\nu } $ whoose are excluded and the optimal value $ R^* $ is $ R^* = \\| \\phi(x_i) - h^* \\|^2, \\forall i \\in M $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\forall x \\in \\mathcal(X) : \\begin{cases}\n",
    "    \\| \\phi(x) - h \\|^2 < R, \\text{ for inlier } \\\\\n",
    "    \\| \\phi(x) - h \\|^2 > R, \\text{ for outlier }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "For detecting and penalized outliers in training set, we should change $ R $, which present the distance from the hyperplane and point and should be not smaller that $ R + \\xi $, where $ \\xi_i $ slack variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.1 (2 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that for some $x_i$ we have $\\|\\phi(x_i) - h\\|^2 < R$.\n",
    "We will call this point **inlier**.\n",
    "\n",
    "* What are the values of $\\alpha_i$ and $\\beta_i$ for such a point?\n",
    "* Show that $1-\\nu$ upper-bounds the sum of weights $C_i$ for the **inlier** points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every inlier, inequality state true: $\\|\\phi(x_i) - h \\|^2 < R + \\xi_i$ and the corresponding Lagrange multiplier:\n",
    "$$\n",
    "\\alpha_i=0, \\quad \\beta_i=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{i \\in \\text{ outlier } } C_i + \\sum_{i \\in \\text{ margin } } C_i + \\sum_{i \\in \\text{ inlier } }C_i = \\sum_i C_i = 1 \\implies \\sum_{i \\in \\text{ inlier } } C_i = 1 - \\left [ \\sum_{i \\in \\text{ margin } } C_i + \\sum_{i \\in \\text{ outlier }  } C_i \\right] \\leq\n",
    "1 - \\sum_{i \\in \\text{ outlier } } C_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result from future task, we have, that for outlier upper bound is:\n",
    "$$\n",
    "\\sum_{i \\in \\text{ outlier } } C_i \\leq \\nu, \\implies 1 - \\sum_{i \\in \\text{ inlier } } C_i \\geq \\nu \\implies 1 - \\nu \\geq \\sum_{i \\in \\text{ inlier } } C_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.2 (2 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that for some $x_i$ it holds that $\\|\\phi(x_i) - h \\|^2 > R$.\n",
    "Such points are called **outliers**.\n",
    "\n",
    "* What are the values of $\\alpha_i$ and $\\beta_i$ for these points?\n",
    "* Argue that the sum of weights $C_i$ for the **outliers** is upper bounded by $\\nu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Every outlier satisfy equality $\\| \\phi(x_i) - h \\|^2 = R + \\xi_i $.\n",
    "$$\n",
    "\\alpha_i=\\frac{C_i}{\\nu}, \\quad \\beta_i>0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the subtask above we have, that $a_i > 0$, then from complementary slackness conditions we have:\n",
    "$$\n",
    "R + \\xi_i  - \\| \\phi(x_i) - h\\|^2 = 0 \\implies \\xi_i = \\| \\phi(x_i) - h \\|^2 - R \\\\\n",
    "R + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\xi_i = R + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i (\\| \\phi(x_i) - h \\|^2 - R) = \\\\ = R + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\| \\phi(x_i) - h \\|^2 - \\sum_{i = 1}^l C_i R = \\\\ = R \\left [ 1 - \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\right ] + \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\| \\phi(x_i) - h\\|^2 \\geq R \\left(1 - \\frac1\\nu \\sum_{i=1}^l C_i \\right) \\geq 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is why:\n",
    "$$ \n",
    "R > \\| \\phi(x_i) - h \\|^2 > 0\n",
    "$$ \n",
    "implies, that:\n",
    "$$\n",
    "1 - \\dfrac{1}{\\nu} \\sum_{i = 1}^l C_i \\geq 0 \\implies \\sum_{i = 1}^l C_i \\leq \\nu\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.3: Very small $\\nu$ (1 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that $\\nu < C_i$ for all $i=1,\\,\\ldots,\\,l$. Show that\n",
    "there are **no outliers** in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous task we have, that for all outliers, we have:\n",
    "$$\n",
    "\\sum_{i \\in \\text{ outliers }} C_i < \\nu \\text{ for outliers } \n",
    "$$\n",
    "Here we have contradiction with previous results, and for holding previous inequality to stay true means, that there are not outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.4 (1 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $C_i = \\tfrac1l$. Please, describe how $\\nu$ is related to the\n",
    "outliers in the datset, given the analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we put $ C = \\dfrac{1}{l} $, than by varying $ \\nu $, we can vary the number of outliers:\n",
    "$$\n",
    "\\sum_{i \\in \\text{ outliers }} C_i = \\sum_{i \\in \\text{ outliers }} < \\nu \\implies\n",
    "$$\n",
    "k - number of outliers and:\n",
    "$$\n",
    "k = \\left [ \\dfrac{\\nu}{\\frac{1}{l}} \\right ] = \\left [ \\nu l \\right ]\n",
    "$$\n",
    "where $ [ a ] $ - integer part of float point number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
